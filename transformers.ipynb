{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahaZainab/Source-Code-Comprehension/blob/main/transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kr3l0pb04GPU"
      },
      "source": [
        "## Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWVCR1iE4GPV",
        "outputId": "d00c48dc-5b1c-4011-e346-b9c6a0d07cf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5GIWwNC44GPW"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, set_seed\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMAHzQCD4GPW"
      },
      "source": [
        "### Initializing the generator model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rKcXXe9L4GPW"
      },
      "outputs": [],
      "source": [
        "def init_model():\n",
        "    generator = pipeline('text-generation', model='EleutherAI/gpt-neo-2.7B')\n",
        "    set_seed(random.randint(0, 10000))\n",
        "    return generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuzxjXSl4GPX"
      },
      "source": [
        "### Function to generate answers based on code and questions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_IGyX76a4GPX"
      },
      "outputs": [],
      "source": [
        "def generate_answer(generator, code_snippet, question):\n",
        "    prompt = f\"Code snippet:\\n{code_snippet}\\n###\\nQuestion: {question}\\nAnswer:\"\n",
        "    answers = generator(prompt, max_length=250, num_return_sequences=1)\n",
        "    return answers[0]['generated_text']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMhHucCX4GPX"
      },
      "source": [
        "### Main function to use the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8KI11lO4GPX",
        "outputId": "1312eee0-49d5-4f74-ed02-da815fd8bac2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated Answer: Code snippet:\n",
            "\n",
            "def MakeSuiteFromDict d label None suite Suite label label suite SetDict d suite Normalize return suite\n",
            "###\n",
            "Question: What does the code make ?\n",
            "Answer: It returns a new suite object from the given dict.\n",
            "\n",
            "A:\n",
            "\n",
            "It looks like it is used to define a new suite.\n",
            "\n",
            "def MakeSuiteFromDict d label None suite Suite label label suite SetDict d suite Normalize return suite\n",
            "###\n",
            "Question: What does the code make?\n",
            "Answer: It returns a new suite object from the given dict.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def main():\n",
        "    code_snippet = \"\"\"\n",
        "def MakeSuiteFromDict d label None suite Suite label label suite SetDict d suite Normalize return suite\"\"\"\n",
        "    question = \"What does the code make ?\"\n",
        "\n",
        "    # Initialize the model\n",
        "    generator = init_model()\n",
        "\n",
        "    # Generate the answer\n",
        "    answer = generate_answer(generator, code_snippet, question)\n",
        "    print(\"Generated Answer:\", answer)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPzqP8t84GPX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
